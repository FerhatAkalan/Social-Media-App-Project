{"ast":null,"code":"import { EndOfStreamError } from 'peek-readable';\nimport { AbstractTokenizer } from './AbstractTokenizer.js';\nexport class BufferTokenizer extends AbstractTokenizer {\n  /**\n   * Construct BufferTokenizer\n   * @param uint8Array - Uint8Array to tokenize\n   * @param fileInfo - Pass additional file information to the tokenizer\n   */\n  constructor(uint8Array, fileInfo) {\n    super(fileInfo);\n    this.uint8Array = uint8Array;\n    this.fileInfo.size = this.fileInfo.size ? this.fileInfo.size : uint8Array.length;\n  }\n  /**\n   * Read buffer from tokenizer\n   * @param uint8Array - Uint8Array to tokenize\n   * @param options - Read behaviour options\n   * @returns {Promise<number>}\n   */\n  async readBuffer(uint8Array, options) {\n    if (options && options.position) {\n      if (options.position < this.position) {\n        throw new Error('`options.position` must be equal or greater than `tokenizer.position`');\n      }\n      this.position = options.position;\n    }\n    const bytesRead = await this.peekBuffer(uint8Array, options);\n    this.position += bytesRead;\n    return bytesRead;\n  }\n  /**\n   * Peek (read ahead) buffer from tokenizer\n   * @param uint8Array\n   * @param options - Read behaviour options\n   * @returns {Promise<number>}\n   */\n  async peekBuffer(uint8Array, options) {\n    const normOptions = this.normalizeOptions(uint8Array, options);\n    const bytes2read = Math.min(this.uint8Array.length - normOptions.position, normOptions.length);\n    if (!normOptions.mayBeLess && bytes2read < normOptions.length) {\n      throw new EndOfStreamError();\n    } else {\n      uint8Array.set(this.uint8Array.subarray(normOptions.position, normOptions.position + bytes2read), normOptions.offset);\n      return bytes2read;\n    }\n  }\n  async close() {\n    // empty\n  }\n}","map":{"version":3,"names":["EndOfStreamError","AbstractTokenizer","BufferTokenizer","constructor","uint8Array","fileInfo","size","length","readBuffer","options","position","Error","bytesRead","peekBuffer","normOptions","normalizeOptions","bytes2read","Math","min","mayBeLess","set","subarray","offset","close"],"sources":["C:/Users/Ferhat/Social-Media-App-Project/wsfrontend/node_modules/strtok3/lib/BufferTokenizer.js"],"sourcesContent":["import { EndOfStreamError } from 'peek-readable';\nimport { AbstractTokenizer } from './AbstractTokenizer.js';\nexport class BufferTokenizer extends AbstractTokenizer {\n    /**\n     * Construct BufferTokenizer\n     * @param uint8Array - Uint8Array to tokenize\n     * @param fileInfo - Pass additional file information to the tokenizer\n     */\n    constructor(uint8Array, fileInfo) {\n        super(fileInfo);\n        this.uint8Array = uint8Array;\n        this.fileInfo.size = this.fileInfo.size ? this.fileInfo.size : uint8Array.length;\n    }\n    /**\n     * Read buffer from tokenizer\n     * @param uint8Array - Uint8Array to tokenize\n     * @param options - Read behaviour options\n     * @returns {Promise<number>}\n     */\n    async readBuffer(uint8Array, options) {\n        if (options && options.position) {\n            if (options.position < this.position) {\n                throw new Error('`options.position` must be equal or greater than `tokenizer.position`');\n            }\n            this.position = options.position;\n        }\n        const bytesRead = await this.peekBuffer(uint8Array, options);\n        this.position += bytesRead;\n        return bytesRead;\n    }\n    /**\n     * Peek (read ahead) buffer from tokenizer\n     * @param uint8Array\n     * @param options - Read behaviour options\n     * @returns {Promise<number>}\n     */\n    async peekBuffer(uint8Array, options) {\n        const normOptions = this.normalizeOptions(uint8Array, options);\n        const bytes2read = Math.min(this.uint8Array.length - normOptions.position, normOptions.length);\n        if ((!normOptions.mayBeLess) && bytes2read < normOptions.length) {\n            throw new EndOfStreamError();\n        }\n        else {\n            uint8Array.set(this.uint8Array.subarray(normOptions.position, normOptions.position + bytes2read), normOptions.offset);\n            return bytes2read;\n        }\n    }\n    async close() {\n        // empty\n    }\n}\n"],"mappings":"AAAA,SAASA,gBAAgB,QAAQ,eAAe;AAChD,SAASC,iBAAiB,QAAQ,wBAAwB;AAC1D,OAAO,MAAMC,eAAe,SAASD,iBAAiB,CAAC;EACnD;AACJ;AACA;AACA;AACA;EACIE,WAAWA,CAACC,UAAU,EAAEC,QAAQ,EAAE;IAC9B,KAAK,CAACA,QAAQ,CAAC;IACf,IAAI,CAACD,UAAU,GAAGA,UAAU;IAC5B,IAAI,CAACC,QAAQ,CAACC,IAAI,GAAG,IAAI,CAACD,QAAQ,CAACC,IAAI,GAAG,IAAI,CAACD,QAAQ,CAACC,IAAI,GAAGF,UAAU,CAACG,MAAM;EACpF;EACA;AACJ;AACA;AACA;AACA;AACA;EACI,MAAMC,UAAUA,CAACJ,UAAU,EAAEK,OAAO,EAAE;IAClC,IAAIA,OAAO,IAAIA,OAAO,CAACC,QAAQ,EAAE;MAC7B,IAAID,OAAO,CAACC,QAAQ,GAAG,IAAI,CAACA,QAAQ,EAAE;QAClC,MAAM,IAAIC,KAAK,CAAC,uEAAuE,CAAC;MAC5F;MACA,IAAI,CAACD,QAAQ,GAAGD,OAAO,CAACC,QAAQ;IACpC;IACA,MAAME,SAAS,GAAG,MAAM,IAAI,CAACC,UAAU,CAACT,UAAU,EAAEK,OAAO,CAAC;IAC5D,IAAI,CAACC,QAAQ,IAAIE,SAAS;IAC1B,OAAOA,SAAS;EACpB;EACA;AACJ;AACA;AACA;AACA;AACA;EACI,MAAMC,UAAUA,CAACT,UAAU,EAAEK,OAAO,EAAE;IAClC,MAAMK,WAAW,GAAG,IAAI,CAACC,gBAAgB,CAACX,UAAU,EAAEK,OAAO,CAAC;IAC9D,MAAMO,UAAU,GAAGC,IAAI,CAACC,GAAG,CAAC,IAAI,CAACd,UAAU,CAACG,MAAM,GAAGO,WAAW,CAACJ,QAAQ,EAAEI,WAAW,CAACP,MAAM,CAAC;IAC9F,IAAK,CAACO,WAAW,CAACK,SAAS,IAAKH,UAAU,GAAGF,WAAW,CAACP,MAAM,EAAE;MAC7D,MAAM,IAAIP,gBAAgB,CAAC,CAAC;IAChC,CAAC,MACI;MACDI,UAAU,CAACgB,GAAG,CAAC,IAAI,CAAChB,UAAU,CAACiB,QAAQ,CAACP,WAAW,CAACJ,QAAQ,EAAEI,WAAW,CAACJ,QAAQ,GAAGM,UAAU,CAAC,EAAEF,WAAW,CAACQ,MAAM,CAAC;MACrH,OAAON,UAAU;IACrB;EACJ;EACA,MAAMO,KAAKA,CAAA,EAAG;IACV;EAAA;AAER"},"metadata":{},"sourceType":"module","externalDependencies":[]}